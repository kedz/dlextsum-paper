%\hal{i would reframe this as:
%  1) the goal of summarization is ...;
%  2) we measure quality of summaries by ...;
%  3) in the sentence extraction approach, we ...;
%  and then i would move the ``ground truth'' part to the experimental section; that's part of how you get data, not part of the problem definition.}
%
\kathy{Overall, this quite a short section. Is it needed? Or should it be morged somewhere else?}

\kathy{Again, I think you have to state that the unit for extraction is the sentence.}
The goal of extractive text summarization is to select a subset of a document's
text to use as a summary, i.e. a short gist or excerpt of the central content.
Typically, we impose a budget on the length of the summary in either 
words or bytes.

We evaluate summary quality using ROUGE \cite{lin2004rouge} 
which measures the ngram
overlap of our predicted extract summary with one or more human abstracts.
We use ROUGE-2 recall (i.e. bigram recall) as our main evaluation metric 
(ROUGE-1 and ROUGE-LCS trend similarity to ROUGE-2 in our experiments).
We also evaluate using METEOR \cite{denkowski:lavie:meteor-wmt:2014}
which measures precision and recall of reference words, while allowing for
more complicated word matchings (e.g. via synonymy or morphology).






In this paper, we model this task as a sequence tagging problem, 
i.e. given a document containing $\docsize$ sentences $\sent_1, \ldots, 
\sent_{\docsize}$ we want to predict a corresponding label sequence $\slabel_1,
\ldots, \slabel_{\docsize} \in \{0, 1\}^{\docsize}$ where $\slabel_i = 1$ 
indicates the $i$-th sentence is to be included in the summary.


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "dlextsum.emnlp18"
%%% End:
