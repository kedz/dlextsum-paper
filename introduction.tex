
%\hal{i feel like you can restructure the intro to focus on you stuff, rather than focusing on how it relates to other people's stuff. just lead with context selection is important for generation, summarization, etc., and is a key compontent both in extractive *and* abstractive techniques. then go to the third paragraph about what you do. you can then relate back to deep learning predictions in the related work section.}

%While there has a been a recent flurry of work on abstractive summarization
%\cite{paulus,see,chenglapata,nallapati},
%these papers treat this problem as a pure sequence to sequence 
%transduction task. Admittedly, this view allows us to apply very powerful, 
%general-purpose deep learning archictures to generate summaries.
%At the same time, it obscures a principal subtask in summarization, the 
%process of selecting the most salient units of meaning in the source material,
%i.e. the key ingredients in the final summary, a process which we 
%broadly refer to as content selection \cite{possiblyMcKeownAndNenkova}.

%As is also the case in other NLP tasks, it is not immediately obvious how a
%deep learning model is making its predictions, or what correlations 
%are being exploited. There is a concerning and growing list of papers that 
%find models functioning as mere nearest neighbors search 
%\cite{liang,danqichen}, exploiting annotator artifacts 
%\cite{recentNaaclPapersOnSNLI}, or open to adversarial exploitation \cite{findExampleYouNoMemoryDumbDumb}. 
%These lines of research are critical for finding model shortcomings, and over
%time, guiding improvements in technique. Unfortunately,
%to the best of our knowledge, there has been
%no such undertaking for the summarization task. 


%\kathy{content selection is very different for generation than for summarization.
%I think you need to initially say that content selection for generation is sentence
%selection. Note that you could be criticized even here as some people may say that
%summarization should be phrase selection (although it rarely is)}
%\kathy{I have also reworded definition of content selection for NLG.}
Content selection is an central component in many natural language generation
%problems, 
tasks,
where, given a generation goal, the system must determine which information
%i.e. given some context, determine which information
should be expressed in output text \cite{gatt2018survey}.
In summarization, content selection is usually accomplished through sentence (and,
occasionally, phrase) extraction.
Despite being a key component of both
extractive and abstractive summarization systems, it is is not well
understood how deep learning models perform content selection with only word and 
sentence
embedding based features as input.
%\hal{i'm not sure what this sentence means, especially the part after ``using'', CK: addressed it, does it work now?}.
%\hal{well understood as a task or in specific models?} 
Non-neural network approaches often use frequency and information theoretic measures as proxies
for content salience \cite{hong2014improving}, but these are not explicitly %\hal{directly? explicitly?} 
used in most neural network summarization systems.
%\hal{maybe instead of recent work say nn systems?}.
% changed wording

%\hal{there are lots of widows/orphans throughout that need to be cleaned up.}

In this paper, we seek to better understand how deep learning models of 
%summarization are performing content selection across a variety of domains.
summarization perform content selection across multiple domains (\S~\ref{sec:datasets}): news, personal stories,
meetings, and medical articles (for which we collect a new corpus).\footnote{Data preprocessing and implementation code can be found here: \url{https://github.com/kedz/nnsum/tree/emnlp18-release}}
%no new paragraph needed here
We analyze
several recent sentence extractive neural network architectures, 
specifically considering the design choices for sentence encoders (\S~\ref{sec:senc})
and sentence extractors (\S~\ref{sec:sext}). We compare Recurrent Neural Network (RNN) and Convolutional Neural
Network (CNN) based sentence representations to the 
simpler approach of word embedding averaging to understand the gains 
derived from more sophisticated architectures.
We also question the necessity of auto-regressive sentence extraction 
(i.e. using previous predictions to inform future predictions), 
which previous approaches have used (\S~\ref{sec:related}),
and propose two alternative models that extract sentences independently.
%
%We compare these architectures against
%a simpler approach based on averaging of word embeddings in order to understand
%the gains derived from more sophisticated architectures.
%
%\kathy{I would find it better to introduce approach here. I've added an
%extra sentence above. Because your experiments reveal the tidbits below by 
%contrasting past approaches with your simple approach which uses embedding
%averages}
%
%
%\kathy{You use some strong words, one of which is ``worrying''. I think it
%may be better toned down. After all, reviewers may be Lapata or Nallapati}
%\kathy{Also, I think it should be pumchier with all learned things itemized.
%For example:
%~
%KM2: Minor changes below
\\[-0.5em]

\noindent
Our main results (\S~\ref{sec:exps}) reveal:
\begin{enumerate}[noitemsep]
\item Sentence position bias dominates the learning signal for news summarization, though not for
    other domains.\footnote{This is a known bias 
    in news summarization \cite{nenkova2005automatic}.}
        %\hal{be consistent on domain/genre. also maybe you should say above what domains you consider?}. 
Summary quality for news is only slightly degraded when content words
are omitted from sentence embeddings. %\hal{this sounds like you remove content words and the summary is still as good. clearly not what's meant. i hope :P.}
\item Word embedding averaging is as good or better than either RNNs or CNNs for sentence embedding across all domains.
\item Pre-trained word embeddings are as good, or better than, learned embeddings in five of six datasets.%\hal{you were specific in the other ones, be specific here too if possible}
\item Non auto-regressive sentence extraction performs as good or better 
     than auto-regressive extraction in all
    domains.
 %   Representation of previously selected summary content does not improve overall summary content. \hal{i think this one might be hard to parse for non-experts. maybe ``explicitly reprsenting prev...''}
\end{enumerate} 

\noindent
Taken together, these and other results in the paper suggest that we are 
over-estimating the ability of deep learning models to learn robust and 
meaningful content features for summarization.  
In one sense, this might lessen the burden of applying neural network models
of  content to other domains; one really just needs in-domain word embeddings.
However, if we want to learn something other than where the start of 
the article is, we will need to design other means of sentence representation,
and possibly external knowledge representations, better suited to the summarization task.


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "dlextsum.emnlp18"
%%% End:
