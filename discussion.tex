
\begin{table*}
\centering
  \begin{tabular}{p{20em} p{20em}}
\toprule
Hurricane Gilbert swept toward the Dominican Republic Sunday, and the 
   Civil Defense alerted its heavily populated south coast to prepare 
   for high winds, heavy rains and high seas.                         
The storm was approaching from the southeast with sustained winds of  
   75 mph gusting to 92 mph.                                          
An estimated 100,000 people live in the province, including 70,000 in 
   the city of Barahona, about 125 miles west of Santo Domingo.       
\textbf{On Saturday, Hurricane Florence was downgraded to a tropical storm and
   its remnants pushed inland from the U.S. Gulf Coast.}               
Tropical Storm Gilbert formed in the eastern Caribbean and            
   strengthened into a hurricane Saturday night.  
&
Hurricane Gilbert swept toward the Dominican Republic Sunday, and the 
   Civil Defense alerted its heavily populated south coast to prepare 
   for high winds, heavy rains and high seas.                         
The storm was approaching from the southeast with sustained winds of  
   75 mph gusting to 92 mph.                                          
An estimated 100,000 people live in the province, including 70,000 in 
   the city of Barahona, about 125 miles west of Santo Domingo.       
Tropical Storm Gilbert formed in the eastern Caribbean and            
   strengthened into a hurricane Saturday night.                      
\textbf{Strong winds associated with the Gilbert brought coastal flooding,    
   strong southeast winds and up to 12 feet feet to Puerto Rico's     
   south coast.}   \\
\bottomrule
\end{tabular}
\caption{Example output of Seq2Seq extractor (left) and Cheng 
\& Lapata Extractor (right). This is a typical example, where only one
 sentence is different between the two (show in bold). }
\label{tab:output}
\end{table*}

Learning in the news domain is severely inhibited by the lead bias. 
The output of all systems is highly similar to each other and to the lead 
baseline. Using the averaging encoder, the Seq2Seq and Cheng \& Lapata
extractors share 87.8\% of output sentences on average on the CNN/DM data,
with similar numbers for the other news domains (see \autoref{tab:output}
for a typical example).  
Also on CNN/DM, 58\% of the Seq2Seq with averaging encoder outputs sentences also occurring
in the lead summary, with similar numbers for DUC, NYT, and Reddit. Shuffling
reduces lead overlap to 35.2\% but the overall system performance drops
    significantly.
    The relative robustness of the news domain to POS ablation also suggests
    suggests that models are mostly learning to recognize the stylistic 
    features unique to the beggining of the article, and not the content.
    Additionally, drop in performance when learning word embeddings on 
    the news domain suggests that word embeddings alone do not provide 
    very generalizable content features compared to recognizing the lead.

The picture is rosier for non-news summarization where POS ablation leads
to larger performance differences and shuffling either does not inhibit content
selection significantly or leads to modest gains. In order to learn better
word-level representations on these domains will likely require much
larger corpora, somthing which might remain unlikely for personal narratives
and meetings.



The lack of distinction amongst sentence encoders is interesting because 
it echoes findings in the generic sentence embedding literature 
where word embedding averaging is frustratingly difficult to 
outperform  \cite{wieting2015towards,arora2016simple,wieting2017revisiting}.
The inability to learn useful sentence representations is also 
borne out in the 
SummaRunner model, where there are explicit similarity computations
between document or summary representations and sentence embeddings;
these computations do not seem to add much to the performance as the 
Cheng \& Lapata and Seq2Seq models which lack these features generally
perform as well or better.
Furthermore, the Cheng \& Lapata and SummaRunner extractors both construct
a history of previous selection decisions to inform future choices but this
does not seem to significantly improve performance over the Seq2Seq extractor 
which does not, suggesting that we need to rethink or find novel forms 
of sentence representation for the summarization task.


A manual examination of the outputs revealed some interesting failure modes
although in general it was hard to discern clear patterns of behaviour 
other than lead bias. On the news domain, the models consistently learned 
to ignore quoted material in the lead, as often the quotes provide
color to the story but are unlikely to be included in the summary (e.g.\textit{``It was like somebody slugging a punching bag.''}). 
This behavior was most likely triggered by the presence of quotes, as the
quote attributions, which were often tokenized as separate sentences,
would subsequently be included in the summary despite also not containing 
much information 
(e.g. \textit{Gil Clark of the National Hurricane Center said Thursday}).




The Reddit corpus was particularly challenging as often there was no concise
way to extractively represent the story. Authors often inserted a 
fairly brief summary of the story, either at the end or beginning, but
this was so abstractive as to not have much overlap with the reference
summaries. For example, the first sentence, \textit{I took a dog off the street, and she changed my grandparent's lives}, has little overlap with the reference
\textit{The dog I found for my grandparents still gets really excited to see
me whenever I come to visit}, but is still functionally a reasonable 
summary of the story. These ``micro summaries'' do not seem to be 
consistently found by any summarization model. 



